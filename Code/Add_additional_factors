{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18yv-WkKRvHxe2h4YPnTnniXRz4XGmNjg","timestamp":1736459341133}],"authorship_tag":"ABX9TyO5AHvXSUEMTOLVfgy6ntbY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EDFSJWqZi4_e"},"outputs":[],"source":["# === SETUP === #\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","from google.colab import drive\n","import sys"]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","folder = '/content/drive/MyDrive/Quantitative Investment Portfolio/'\n","data_dir = '/content/drive/MyDrive/Quantitative Investment Portfolio/Data/'\n","f_dir = os.path.join(folder,'Data Release 2024.10/Firm Level Characteristics/Individual/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pJ7ExV7jKQj","executionInfo":{"status":"ok","timestamp":1736457381504,"user_tz":300,"elapsed":18211,"user":{"displayName":"Kshitiz Udainiya","userId":"12017166330131371347"}},"outputId":"616bcfcd-de84-431b-e6fe-8460c9d02b45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_d = pd.read_parquet(data_dir + 'final_factors.parquet')\n","data_divison = {'insample':[1993,2013],'outsample':[2013,2024],'presample':[1990,1992]}"],"metadata":{"id":"eObupJ39KbLX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["factor = ['Placebos/AssetTurnover.csv']\n","for f in factor:\n","  dff = pd.read_csv(f_dir + f)\n","  data_d = pd.merge(data_d,dff,on=['permno','yyyymm'],how='left')\n","col = data_d.columns[-len(factor):].tolist()"],"metadata":{"id":"oP4XKWYVDL3X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_d = cleaningpipeline(data_d,data_divison,col=col)"],"metadata":{"id":"i4zn9W3iDwCQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ubound(x,dx=0.01,dy=0.01):\n","    data_range = x.max() - x.min()\n","    near_max = x >= (x.max() - dx * data_range)  # 1% below max\n","    if(near_max.mean()>0.01):return 1\n","    return 0\n","def lbound(x,dx=0.01):\n","    data_range = x.max() - x.min()\n","    near_min = x <= (x.min() + dx * data_range)  # 1% above min\n","    if(near_min.mean()>0.01):return 1\n","    return 0\n","\n","def handle_outliers(data, q=[0.005,0.995], max_missing=2):\n","    data_clip = data.loc[:,data.nunique()>10].copy()\n","    l = data_clip.quantile(q[0],axis=0)\n","    u = data_clip.quantile(q[1],axis=0)\n","\n","    cols = data_clip.apply(ubound)\n","    cols = cols[cols>0]\n","    u[cols.index] = np.inf\n","\n","    cols = data_clip.apply(lbound)\n","    cols = cols[cols>0]\n","    l[cols.index] = -np.inf\n","\n","    data_clip = data_clip.clip(lower=l, upper=data_clip.quantile(q[1],axis=0),axis='columns')\n","    outs = data_clip.apply(is_out)\n","    outB = outs.sum(axis=1) > max_missing\n","    data_clip = data_clip[~outB]\n","\n","    return data_clip"],"metadata":{"id":"vrdgpogpWry4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def is_out(x):\n","    return abs(x - x.mean()) > x.std() * 3\n","\n","def annoy(x):\n","    if(x.size<2):return (x-x)\n","    x_std = x.std()\n","    if(x_std in [0, np.nan]):return (x-x)\n","    y = (x - x.mean())/x_std\n","    return y\n","\n","def data_cleaning(df,cols,drop_financials=True):\n","    print(f'Starting rows: {df.shape[0]}')\n","    if(cols is None):cols = df.columns[2:-4]\n","    ## Ok now lets start with data preprocessing\n","    ### First we will remove outliers\n","\n","    df = handle_outliers(df[cols])\n","\n","    if(drop_financials):\n","        # Drop Financial and Unclassified industry stocks\n","        df = df[df['ind']!=48]\n","        df = df[df['ind']!=50]\n","\n","    print(df.shape[0])\n","\n","    # Ok Now we Z-score the data by year and Industry except TK only by year\n","    zfactors = []\n","\n","    for i in cols:\n","        if(i=='TK'):\n","            df['z'+ 'TK'] = df.groupby(['year'])['TK'].transform(annoy)\n","            zfactors.append('z'+'TK')\n","            continue\n","        df['z'+ i] = df.groupby(['year', 'ind'])[i].transform(annoy)\n","        zfactors.append('z'+i)\n","\n","    print(f'Ending rows: {df.shape[0]}')\n","    df = df.reset_index(drop=True)\n","    return df,zfactors"],"metadata":{"id":"XNx2jerAU6EV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cleaningpipeline(data,data_divison,cols,drop_financials=True):\n","    insample  = data[(data['year']>=data_divison['insample'][0])  & (data['year']<data_divison['insample'][1])]\n","    outsample = data[(data['year']>=data_divison['outsample'][0]) & (data['year']<data_divison['outsample'][1])]\n","    presample = data[(data['year']>=data_divison['presample'][0]) & (data['year']<data_divison['presample'][1])]\n","\n","    insample, zfactors  = data_cleaning(insample, cols,drop_financials)\n","    outsample, _ = data_cleaning(outsample,cols,drop_financials)\n","    presample, _ = data_cleaning(presample,cols,drop_financials)\n","\n","    insample['s']  =  0\n","    outsample['s'] =  1\n","    presample['s'] =  2\n","\n","    data_d = pd.concat([insample,outsample,presample])\n","    data_d = data_d.drop(columns=cols)\n","    return data_d"],"metadata":{"id":"my_n6mmCaJC_"},"execution_count":null,"outputs":[]}]}